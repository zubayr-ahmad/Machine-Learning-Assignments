{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 IRS - With Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have initialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n",
    "dir_path = './files'          # dir_path to store the path of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here  \n",
    "\n",
    "# 1. counting number of files in the directory \n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)) and path != 'synonyms.txt':\n",
    "        file_count += 1\n",
    "# print('File count:', file_count)\n",
    "\n",
    "# 2. counting the number of words in each file\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)) and path != 'synonyms.txt':\n",
    "        with open(os.path.join(dir_path, path), 'r') as file:\n",
    "            # read the file and split the words\n",
    "            words = file.read().split()\n",
    "            # store the count of words in the dictionary\n",
    "            files_dict[path] = len(words)\n",
    "# print('Files dictionary:', files_dict)\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 4, 'f2.txt': 4, 'f3.txt': 4}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique word set: {'book', 'this', 'is', 'interesting', 'my', 'pen'}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "# 3. Getting the unique words from all the files\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)) and path != 'synonyms.txt':\n",
    "        with open(os.path.join(dir_path, path), 'r') as file:\n",
    "            # read the file and split the words\n",
    "            words = file.read().split()\n",
    "            lowercase_words = np.char.lower(words)\n",
    "            # add the words to the set\n",
    "            unique_word_set.update(lowercase_words)\n",
    "print('Unique word set:', unique_word_set)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "2. Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "{'book': 0, 'this': 1, 'is': 2, 'interesting': 3, 'my': 4, 'pen': 5}\n",
      "{'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "# Creating a matrix of size (number of files) x (number of unique words) and storing the count of each word in each file\n",
    "matrix = np.zeros((file_count, len(unique_word_set)))\n",
    "print(matrix)   \n",
    "dict_of_files = {}\n",
    "dict_unique_words = {}\n",
    "unique_words_list = list(unique_word_set)\n",
    "for idx,val in enumerate(unique_word_set):\n",
    "    dict_unique_words[val] = idx\n",
    "print(dict_unique_words)\n",
    "\n",
    "for i,file in enumerate(files_dict):\n",
    "    dict_of_files[file] = i\n",
    "print(dict_of_files)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "2. If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "3. Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book': 0, 'this': 1, 'is': 2, 'interesting': 3, 'my': 4, 'pen': 5}\n",
      "[[1. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)) and path != 'synonyms.txt':\n",
    "        with open(os.path.join(dir_path, path), 'r') as file:\n",
    "            # read the file and split the words\n",
    "            words = file.read().split()\n",
    "            for word in words:\n",
    "                matrix[dict_of_files[path], dict_unique_words[word.lower()]] += 1\n",
    "print(dict_unique_words)\n",
    "print(matrix)\n",
    "\n",
    "# Because set does not have specific order so output is a little different but logically is correct\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "colVector = np.zeros((len(dict_unique_words),1))\n",
    "colVector\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: fascinating publication\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching:  \")\n",
    "print(\"Query is:\", query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Expected Output of query](images/Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Load Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synonyms Dictionary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'write': ['compose', 'draft', 'author', 'create'],\n",
       " 'file': ['document', 'record', 'dossier', 'report'],\n",
       " 'example': ['illustration', 'instance', 'sample', 'demonstration'],\n",
       " 'query': ['question', 'inquiry', 'search', 'request'],\n",
       " 'synonym': ['equivalent', 'substitute', 'alternate', 'replacement'],\n",
       " 'retrieve': ['fetch', 'recover', 'obtain', 'bring back'],\n",
       " 'system': ['framework', 'structure', 'organization', 'arrangement'],\n",
       " 'search': ['seek', 'look for', 'explore', 'examine'],\n",
       " 'lost': ['misplaced', 'missing', 'forgotten', 'mislaid'],\n",
       " 'pen': ['write', 'ink', 'ballpoint', 'fountain'],\n",
       " 'paper': ['document', 'sheet', 'form', 'letter'],\n",
       " 'book': ['novel', 'volume', 'publication', 'tome'],\n",
       " 'read': ['peruse', 'scan', 'study', 'look at'],\n",
       " 'interesting': ['fascinating', 'engaging', 'intriguing', 'absorbing'],\n",
       " 'computer': ['machine', 'device', 'processor', 'laptop'],\n",
       " 'software': ['program', 'application', 'app', 'platform']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_file_path = r\"files\\synonyms.txt\"\n",
    "synonyms_dict = {} # dictionary to store synonyms\n",
    "#your code starts here\n",
    "with open(synonym_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        key,values = line.split(':')\n",
    "        values = values.strip()\n",
    "        values = values.split(',')\n",
    "        values = [val.strip() for val in values]\n",
    "        synonyms_dict[key] = values\n",
    "\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"\\nSynonyms Dictionary\\n\")\n",
    "synonyms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Synonym Dict Example](images\\Synonym_dict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Extend User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fascinating', 'publication']\n",
      "Expanded Query\n",
      "['interesting', 'fascinating', 'book', 'publication']\n"
     ]
    }
   ],
   "source": [
    "expanded_query = []\n",
    "# Write code to expand the query using synonyms\n",
    "#your code starts here\n",
    "query_list = query.split()\n",
    "print(query_list)\n",
    "\n",
    "for word in query_list:\n",
    "    for key,values in synonyms_dict.items():\n",
    "        if word in values:\n",
    "            expanded_query.append(key)\n",
    "            break\n",
    "    expanded_query.append(word)\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"Expanded Query\")\n",
    "print(expanded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Extended Query](images\\Expanded_Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now work with extended query and find the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exists then increment the count of that word in word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'book': 0, 'this': 1, 'is': 2, 'interesting': 3, 'my': 4, 'pen': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "for word in expanded_query:\n",
    "    lower_word = word.lower()\n",
    "    if lower_word in dict_unique_words:\n",
    "        colVector[dict_unique_words[lower_word]] = 1\n",
    "\n",
    "print(colVector)\n",
    "dict_unique_words\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [2.]]\n",
      "max_index: 2\n",
      "max_value: [2.]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "result = np.dot(matrix, colVector)\n",
    "print(result)\n",
    "index = np.argmax(result)\n",
    "print('max_index:', index)\n",
    "print('max_value:', result[index])\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_name(dictionary, target_index):\n",
    "    for file_name, index in dictionary.items():\n",
    "        if index == target_index:\n",
    "            return file_name\n",
    "    return None  # Return None if the index is not found in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My book is interesting\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "file_name = find_file_name(dict_of_files, index)\n",
    "with open(os.path.join(dir_path, file_name), 'r') as file:\n",
    "    print(file.read())\n",
    "#Your code ends here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS which can work even if query does not have exact same words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
